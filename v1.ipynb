{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLoGCkZfn5nR4Mrpo/uaRk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alisa7979/20252R0136DATA30400/blob/main/v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from collections import defaultdict\n",
        "import networkx as nx\n",
        "import openai\n",
        "\n",
        "# ==========================================\n",
        "# 1. Configuration\n",
        "# ==========================================\n",
        "CONFIG = {\n",
        "    'seed': 42,\n",
        "    'max_len': 128,\n",
        "    'batch_size': 16,\n",
        "    'epochs': 4,\n",
        "    'lr': 2e-5,\n",
        "    'silver_threshold': 1,\n",
        "    'pseudo_conf_threshold': 0.70,\n",
        "    'consistency_weight': 1.0,\n",
        "    'num_classes': 531,\n",
        "    'model_name': 'bert-base-uncased',\n",
        "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(CONFIG['seed'])\n",
        "print(f\"Device: {CONFIG['device']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2NppWSIGYQD",
        "outputId": "8d9e6b0b-8a26-41e1-d7f6-5268a4c63660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. Data Loading & Silver Labels (Regex)\n",
        "# ==========================================\n",
        "def load_data():\n",
        "    print(\"Loading data files...\")\n",
        "    classes_df = pd.read_csv('classes.txt', sep='\\t', header=None, names=['id', 'name'])\n",
        "    id2name = dict(zip(classes_df['id'], classes_df['name']))\n",
        "    name2id = dict(zip(classes_df['name'], classes_df['id']))\n",
        "\n",
        "    hierarchy_df = pd.read_csv('class_hierarchy.txt', sep='\\t', header=None, names=['parent', 'child'])\n",
        "\n",
        "    class_keywords = {}\n",
        "    with open('class_related_keywords.txt', 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if ':' in line:\n",
        "                cls_name, keywords = line.strip().split(':')\n",
        "                if cls_name in name2id:\n",
        "                    class_keywords[name2id[cls_name]] = keywords.split(',')\n",
        "\n",
        "    train_df = pd.read_csv('train_corpus.txt', sep='\\t', header=None, names=['id', 'text'], on_bad_lines='skip')\n",
        "    test_df = pd.read_csv('test_corpus.txt', sep='\\t', header=None, names=['id', 'text'], on_bad_lines='skip')\n",
        "\n",
        "    return classes_df, id2name, name2id, hierarchy_df, class_keywords, train_df, test_df"
      ],
      "metadata": {
        "id": "mnM8P55QsBDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. Silver\n",
        "# ==========================================\n",
        "def generate_silver_labels_with_hierarchy(train_df, class_keywords, hierarchy_df, threshold=1):\n",
        "    print(\"Generating Silver Labels with Hierarchy Expansion...\")\n",
        "\n",
        "    # 1. Build Ancestor Graph\n",
        "    G = nx.DiGraph()\n",
        "    for _, row in hierarchy_df.iterrows():\n",
        "        G.add_edge(row['parent'], row['child'])\n",
        "\n",
        "    # Pre-compute ancestors for speed\n",
        "    node_ancestors = {node: nx.ancestors(G, node) for node in G.nodes()}\n",
        "\n",
        "    # 2. Compile Regex\n",
        "    keyword_patterns = {}\n",
        "    for cls_id, keywords in class_keywords.items():\n",
        "        pattern = re.compile(r'\\b(' + '|'.join([re.escape(k) for k in keywords]) + r')\\b')\n",
        "        keyword_patterns[cls_id] = pattern\n",
        "\n",
        "    silver_data = []\n",
        "    for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
        "        text = str(row['text']).lower()\n",
        "        labels = set()\n",
        "\n",
        "        # Match Keywords\n",
        "        for cls_id, pattern in keyword_patterns.items():\n",
        "            if pattern.search(text):\n",
        "                labels.add(cls_id)\n",
        "\n",
        "        # EXPANSION: Add Parents\n",
        "        parents_to_add = set()\n",
        "        for label in labels:\n",
        "            if label in node_ancestors:\n",
        "                parents_to_add.update(node_ancestors[label])\n",
        "        labels.update(parents_to_add)\n",
        "\n",
        "        # Filter Noise\n",
        "        if labels and len(labels) <= 8:\n",
        "            silver_data.append({\n",
        "                'text': row['text'],\n",
        "                'labels': list(labels),\n",
        "                'is_pseudo': False\n",
        "            })\n",
        "\n",
        "    print(f\"Generated {len(silver_data)} rich silver samples.\")\n",
        "    return silver_data"
      ],
      "metadata": {
        "id": "Pxhfj41me9VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. Model & Graph Definitions\n",
        "# ==========================================\n",
        "def build_adjacency_matrix(num_classes, hierarchy_df):\n",
        "    adj = torch.eye(num_classes)\n",
        "    for _, row in hierarchy_df.iterrows():\n",
        "        p, c = row['parent'], row['child']\n",
        "        if p < num_classes and c < num_classes:\n",
        "            adj[p, c] = 1.0\n",
        "            adj[c, p] = 1.0\n",
        "    deg = torch.sum(adj, dim=1)\n",
        "    d_inv_sqrt = torch.diag(torch.pow(deg, -0.5))\n",
        "    return torch.mm(torch.mm(d_inv_sqrt, adj), d_inv_sqrt).to(CONFIG['device'])\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, num_classes, max_len=128, is_test=False):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.num_classes = num_classes\n",
        "        self.max_len = max_len\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        text = str(item['text']) if isinstance(item, dict) else str(item)\n",
        "        enc = self.tokenizer.encode_plus(text, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        out = {'input_ids': enc['input_ids'].flatten(), 'attention_mask': enc['attention_mask'].flatten()}\n",
        "        if not self.is_test:\n",
        "            lbl = torch.zeros(self.num_classes)\n",
        "            for l in item['labels']:\n",
        "                if l < self.num_classes: lbl[int(l)] = 1.0\n",
        "            out['labels'] = lbl\n",
        "        return out\n",
        "\n",
        "class BertGNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, adj_matrix, model_name='bert-base-uncased'):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.adj = adj_matrix\n",
        "        self.class_emb = nn.Parameter(torch.Tensor(num_classes, 768))\n",
        "        nn.init.xavier_uniform_(self.class_emb)\n",
        "        self.gnn_weight = nn.Parameter(torch.Tensor(768, 768))\n",
        "        nn.init.xavier_uniform_(self.gnn_weight)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = self.drop(out.last_hidden_state[:, 0, :])\n",
        "        # GNN Step: Aggregate neighbor info\n",
        "        class_feat = torch.tanh(torch.mm(torch.mm(self.adj, self.class_emb), self.gnn_weight))\n",
        "        logits = torch.mm(pooled, class_feat.t())\n",
        "        return logits"
      ],
      "metadata": {
        "id": "BcSe3Xk7skJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. LLM Labeling\n",
        "# ==========================================\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def generate_llm_labels_active(train_df, silver_data, id2name, sample_size=500):\n",
        "    # Identify \"Hard\" examples (rows that Regex failed to label)\n",
        "    silver_texts = set(d['text'] for d in silver_data)\n",
        "    hard_df = train_df[~train_df['text'].isin(silver_texts)]\n",
        "\n",
        "    print(f\"Found {len(hard_df)} hard examples. Sampling {sample_size} for LLM...\")\n",
        "    if len(hard_df) > sample_size:\n",
        "        subset = hard_df.sample(n=sample_size, random_state=42)\n",
        "    else:\n",
        "        subset = hard_df\n",
        "\n",
        "    taxonomy_str = \"\\n\".join([f\"{i}: {name}\" for i, name in id2name.items()])\n",
        "    llm_data = []\n",
        "    logs = []\n",
        "\n",
        "    for idx, row in tqdm(subset.iterrows(), total=len(subset)):\n",
        "        text = str(row['text'])[:1000]\n",
        "        user_msg = f\"\"\"Classify into 2-3 categories. JSON format: {{\"labels\": [12, 45]}}\\nReview: \"{text}\"\\nTaxonomy:\\n{taxonomy_str}\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = openai.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[{\"role\": \"system\", \"content\": \"JSON only.\"}, {\"role\": \"user\", \"content\": user_msg}],\n",
        "                response_format={\"type\": \"json_object\"}, temperature=0, max_tokens=100\n",
        "            )\n",
        "            content = response.choices[0].message.content\n",
        "            logs.append({\"id\": row['id'], \"prompt\": user_msg, \"output\": content})\n",
        "\n",
        "            data = json.loads(content)\n",
        "            labels = [int(l) for l in data.get(\"labels\", []) if int(l) < 531]\n",
        "            if labels:\n",
        "                llm_data.append({'text': row['text'], 'labels': labels, 'is_pseudo': False})\n",
        "        except:\n",
        "            time.sleep(1)\n",
        "\n",
        "    with open(\"llm_logs.json\", \"w\") as f: json.dump(logs, f)\n",
        "    return llm_data"
      ],
      "metadata": {
        "id": "1i0sQ8gRsiFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_df, id2name, name2id, hierarchy_df, class_keywords, train_df, test_df = load_data()\n",
        "adj_matrix = build_adjacency_matrix(CONFIG['num_classes'], hierarchy_df)\n",
        "silver_data = generate_silver_labels_with_hierarchy(train_df, class_keywords, hierarchy_df)\n",
        "print(f\"Silver Label Training Samples: {len(silver_data)}\")\n",
        "\n",
        "llm_data = generate_llm_labels_active(train_df, silver_data, id2name, sample_size=500)\n",
        "silver_data += llm_data\n",
        "print(f\"Silver + LLM Training Samples: {len(silver_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbQKcn3AfN7J",
        "outputId": "0736e39f-9c08-45d2-ff06-2bfb88c05ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data files...\n",
            "Generating Silver Labels with Hierarchy Expansion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29487/29487 [03:22<00:00, 145.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 14477 rich silver samples.\n",
            "Silver Label Training Samples: 14477\n",
            "Found 15010 hard examples. Sampling 500 for LLM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [08:23<00:00,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silver + LLM Training Samples: 14924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. Training with Class Weights & Consistency\n",
        "# ==========================================\n",
        "\n",
        "# 1. Calculate Class Weights (CRITICAL for Macro-F1)\n",
        "label_counts = torch.zeros(CONFIG['num_classes'])\n",
        "for item in silver_data:\n",
        "    for label in item['labels']:\n",
        "        label_counts[int(label)] += 1\n",
        "\n",
        "label_counts = torch.clamp(label_counts, min=1)\n",
        "pos_weights = len(silver_data) / (CONFIG['num_classes'] * label_counts)\n",
        "pos_weights = torch.clamp(pos_weights, max=20.0).to(CONFIG['device'])"
      ],
      "metadata": {
        "id": "VymmOSkwgBUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Setup Model\n",
        "tokenizer = BertTokenizer.from_pretrained(CONFIG['model_name'])\n",
        "model = BertGNNClassifier(CONFIG['num_classes'], adj_matrix).to(CONFIG['device'])\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG['lr'])\n",
        "\n",
        "train_dataset = ReviewDataset(silver_data, tokenizer, CONFIG['num_classes'])\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, 0, len(train_loader)*CONFIG['epochs'])"
      ],
      "metadata": {
        "id": "Ak5UUpqVgEh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Weighted BCE Loss\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "print(\"\\n--- Phase 1: Supervised Training ---\")\n",
        "for epoch in range(CONFIG['epochs']):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        ids = batch['input_ids'].to(CONFIG['device'])\n",
        "        mask = batch['attention_mask'].to(CONFIG['device'])\n",
        "        targets = batch['labels'].to(CONFIG['device'])\n",
        "\n",
        "        # Consistency Reg: Two forward passes\n",
        "        logits_1 = model(ids, mask)\n",
        "        logits_2 = model(ids, mask)\n",
        "\n",
        "        cls_loss = criterion(logits_1, targets)\n",
        "        cons_loss = F.mse_loss(torch.sigmoid(logits_1), torch.sigmoid(logits_2))\n",
        "        loss = cls_loss + (CONFIG['consistency_weight'] * cons_loss)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss: {np.mean(losses):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3oNFQGwfhIT",
        "outputId": "cf467e49-f6a0-40c9-8588-af93b622f4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 1: Supervised Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 933/933 [10:51<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 0.0493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  20%|█▉        | 184/933 [02:08<08:45,  1.42it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Phase 2: Self-Training\n",
        "print(\"\\n--- Phase 2: Self-Training ---\")\n",
        "model.eval()\n",
        "unlabeled_dataset = ReviewDataset(train_df['text'].tolist(), tokenizer, CONFIG['num_classes'], is_test=True)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "pseudo_data = []\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(unlabeled_loader, desc=\"Pseudo-labeling\")):\n",
        "        ids = batch['input_ids'].to(CONFIG['device'])\n",
        "        mask = batch['attention_mask'].to(CONFIG['device'])\n",
        "        probs = torch.sigmoid(model(ids, mask)).cpu().numpy()\n",
        "\n",
        "        for j, p in enumerate(probs):\n",
        "            indices = np.where(p > CONFIG['pseudo_conf_threshold'])[0]\n",
        "            if len(indices) >= 2:\n",
        "                 pseudo_data.append({'text': train_df.iloc[i*16+j]['text'], 'labels': indices.tolist()})\n",
        "\n",
        "print(f\"Retraining on {len(silver_data) + len(pseudo_data)} samples...\")\n",
        "combined_loader = DataLoader(ReviewDataset(silver_data + pseudo_data, tokenizer, CONFIG['num_classes']), batch_size=16, shuffle=True)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "for epoch in range(2):\n",
        "    model.train()\n",
        "    for batch in tqdm(combined_loader, desc=f\"Self-Train Epoch {epoch+1}\"):\n",
        "        ids, mask, targets = batch['input_ids'].to(CONFIG['device']), batch['attention_mask'].to(CONFIG['device']), batch['labels'].to(CONFIG['device'])\n",
        "        loss = criterion(model(ids, mask), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "Jknqo3q-fkOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 7. Final Inference\n",
        "# ==========================================\n",
        "print(\"\\n--- Inference on Test Set ---\")\n",
        "test_loader = DataLoader(ReviewDataset(test_df['text'].tolist(), tokenizer, CONFIG['num_classes'], is_test=True), batch_size=16, shuffle=False)\n",
        "model.eval()\n",
        "preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        ids = batch['input_ids'].to(CONFIG['device'])\n",
        "        mask = batch['attention_mask'].to(CONFIG['device'])\n",
        "        probs = torch.sigmoid(model(ids, mask)).cpu().numpy()\n",
        "\n",
        "        for p in probs:\n",
        "            # Sort descending\n",
        "            top = p.argsort()[::-1]\n",
        "\n",
        "            # MANDATORY: Take Top 2\n",
        "            final = [top[0], top[1]]\n",
        "\n",
        "            # CONDITIONAL: Take 3rd if confident (> 0.4) OR relatively close to 2nd\n",
        "            # This helps recall for multi-label cases\n",
        "            if p[top[2]] > 0.4 or (p[top[2]] > 0.7 * p[top[1]]):\n",
        "                final.append(top[2])\n",
        "\n",
        "            preds.append(\",\".join(str(x) for x in sorted(final)))\n",
        "\n",
        "pd.DataFrame({'id': test_df['id'], 'label': preds}).to_csv('submission.csv', index=False)\n",
        "print(\"Saved submission.csv\")"
      ],
      "metadata": {
        "id": "dKNl7NeBsnqi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}